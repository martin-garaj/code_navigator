header:
  title: ggml_tensor
  titlePrefix: /ggml/include/ggml.h
  permalink: https://github.com/ggerganov/llama.cpp/blob/acb2c32c336ce60d765bb189563cc216e57e9fc2/ggml/include/ggml.h#L581

sections:
  - sectionTag: 
    header: 
      title: ggml_tensor
      titlePrefix: 
      permalink: 
    links:
    content:
      syntaxHighlight: cpp
      text: |
        struct ggml_tensor {
            enum ggml_type type;

            GGML_DEPRECATED(enum ggml_backend_type backend, "use the buffer type to find the storage location of the tensor");

            struct ggml_backend_buffer * buffer;

            int64_t ne[GGML_MAX_DIMS]; // number of elements
            size_t  nb[GGML_MAX_DIMS]; // stride in bytes:
                                      // nb[0] = ggml_type_size(type)
                                      // nb[1] = nb[0]   * (ne[0] / ggml_blck_size(type)) + padding
                                      // nb[i] = nb[i-1] * ne[i-1]

            // compute data
            enum ggml_op op;

            // op params - allocated as int32_t for alignment
            int32_t op_params[GGML_MAX_OP_PARAMS / sizeof(int32_t)];

            int32_t flags;

            struct ggml_tensor * grad;
            struct ggml_tensor * src[GGML_MAX_SRC];

            // source tensor and offset for views
            struct ggml_tensor * view_src;
            size_t               view_offs;

            void * data;

            char name[GGML_MAX_NAME];

            void * extra; // extra things e.g. for ggml-cuda.cu

            // char padding[4];
        };